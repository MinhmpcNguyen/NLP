import os
import json
import numpy as np
import matplotlib.pyplot as plt
from pinecone import Pinecone
from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI
import time

# ‚úÖ 1Ô∏è‚É£ C·∫•u h√¨nh API Keys & Model
os.environ["AZURE_OPENAI_API_KEY"] = "d539368d17bc4f609be5f18006f25800"
os.environ["AZURE_OPENAI_ENDPOINT"] = "https://openai-centic.openai.azure.com/"
os.environ["AZURE_OPENAI_API_VERSION"] = "2024-08-01-preview"

# ‚úÖ 2Ô∏è‚É£ Kh·ªüi t·∫°o Pinecone v√† m√¥ h√¨nh
pinecone = Pinecone(
    api_key="pcsk_4TwtQV_Qw2EeFkAvMDx3JURRUaCNetDU2XdqJGqm3e8dxA5SJdsFVTd36tVBpEJuw1UXCk"
)
index_name = "concurrent-vector-20-no-key"
index = pinecone.Index(index_name)

embedder = AzureOpenAIEmbeddings(
    azure_deployment="text-embedding-3-small",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    api_version=os.getenv("AZURE_OPENAI_API_VERSION")
)

llm = AzureChatOpenAI(
    azure_deployment="gpt-4o",
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    api_version=os.getenv("AZURE_OPENAI_API_VERSION")
)

# ‚úÖ 3Ô∏è‚É£ Hybrid Search & Reranking
def content_only_search(user_query, top_k=100):
    """üîç T√¨m ki·∫øm v·ªõi s·ªë l∆∞·ª£ng k·∫øt qu·∫£ l·ªõn ƒë·ªÉ t√≠nh to√°n ph√¢n ph·ªëi similarity"""
    query_vector = embedder.embed_query(user_query)
    chunk_results = index.query(
        vector=query_vector,
        filter={"content": {"$exists": True}},
        top_k=top_k,
        include_metadata=True
    )
    results = chunk_results["matches"]
    return results


def determine_threshold_strategy(similarities):
    """üìä T·ª± ƒë·ªông ch·ªçn ph∆∞∆°ng ph√°p t√≠nh threshold d·ª±a tr√™n ph√¢n b·ªë d·ªØ li·ªáu"""
    mean_sim = np.mean(similarities)
    std_dev_sim = np.std(similarities)
    skewness = (3 * (mean_sim - np.median(similarities))) / std_dev_sim  # ƒê√°nh gi√° ƒë·ªô l·ªách
    
    GM = np.exp(np.mean(np.log(similarities)))  # Trung b√¨nh h√¨nh h·ªçc
    
    if abs(skewness) < 0.5:
        return mean_sim  # Normal distribution (d√πng AM)
    elif skewness > 0.5:
        return GM  # Positively skewed: Ch·ªâ l·∫•y nh·ªØng ƒëi·ªÉm similarity cao d·ª±a tr√™n GM
    elif skewness < -0.5:
        return GM - 0.5 * std_dev_sim  # Negatively skewed: Gi·ªØ g·∫ßn nh∆∞ t·∫•t c·∫£ ƒëi·ªÉm cao, ch·ªâ b·ªè ƒëi·ªÉm th·∫•p d·ª±a tr√™n GM
    else:
        Q1 = np.percentile(similarities, 25)
        Q3 = np.percentile(similarities, 75)
        IQR = Q3 - Q1
        return Q3 + 1.5 * IQR  # D√πng IQR ƒë·ªÉ x·ª≠ l√Ω outliers


def rerank_results(results, threshold):
    """üìå L·ªçc v√† rerank k·∫øt qu·∫£ d·ª±a tr√™n threshold"""
    filtered_results = [item for item in results if item["score"] >= threshold]
    filtered_results.sort(key=lambda x: x["score"], reverse=True)
    return filtered_results


def search_and_generate_answer(user_query):
    """T√¨m ki·∫øm trong Pinecone, √°p d·ª•ng Rerank v√† t·∫°o c√¢u tr·∫£ l·ªùi v·ªõi LLM"""
    start_time = time.time()
    results = content_only_search(user_query, top_k=100)
    similarities = np.array([item["score"] for item in results])
    threshold = determine_threshold_strategy(similarities)
    filtered_results = rerank_results(results, threshold)
    final_results = filtered_results
    retrieved_chunks = [item["metadata"]["content"] for item in final_results]
    retrieved_context = "\n".join(retrieved_chunks)
    prompt = f"""
    You are an AI assistant answering questions based on provided context.
    Context:
    {retrieved_context}
    User's Question:
    {user_query}
    Answer:
    """
    response = llm.invoke(prompt)
    total_time = time.time() - start_time
    return {
        "query": user_query,
        "results": final_results,
        "answer": response.content,
        "execution_time": total_time
    }

# ‚úÖ **6Ô∏è‚É£ Ch·∫°y t√¨m ki·∫øm v·ªõi t·∫≠p c√¢u h·ªèi**
if __name__ == "__main__":
    user_query = "What is Trava Finance and what services does it provide?"
    result = search_and_generate_answer(user_query)
    print(result)
